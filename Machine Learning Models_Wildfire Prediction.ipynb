{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn import linear_model, model_selection, metrics, random_projection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data ready for models\n",
    "cord_all_clean = pd.read_csv('dash_clean.csv')\n",
    "model_firedata = cord_all_clean\n",
    "model_firedata['stat_cause_code'] = model_firedata['stat_cause_code'].astype(int)\n",
    "\n",
    "# filtering out fires with missing cause\n",
    "model_firedata = model_firedata[model_firedata['stat_cause_code'] != 13]\n",
    "\n",
    "# Categorize cause --> 1 is caused by nature, 2 is caused by human\n",
    "model_firedata['human_caused'] = 1\n",
    "model_firedata.loc[model_firedata['stat_cause_code'] > 1 , 'human_caused'] = 2\n",
    "\n",
    "# classify the fire size\n",
    "model_firedata.loc[model_firedata['fire_size'] <= 2.5, 'fire_severity'] = 1\n",
    "model_firedata.loc[(model_firedata['fire_size'] > 2.5) & (model_firedata['fire_size'] <= 100), 'fire_severity'] = 2\n",
    "model_firedata.loc[model_firedata['fire_size'] > 100, 'fire_severity'] = 3\n",
    "\n",
    "model_firedata = model_firedata[model_firedata['D3'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide on features and label\n",
    "Features are latitude, longitude, month the fire happened, year the fire happened, drought, and the acres burned level of the fire.\n",
    "Label is if the fire is caused by human related or nature related reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_severity = model_firedata['human_caused']\n",
    "train_cols = ['latitude', 'longitude', 'fire_month', 'fire_year','D3', 'fire_severity']\n",
    "train_firedata = model_firedata[train_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split and SMOTE\n",
    "\n",
    "85% of wildfires are caused by human related reasons, resulting in an imbalanced dataset for making predictions. Here we use a technique called SMOTE (Synthetic Minority Over-sampling Technique) to deal with the imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(train_firedata, label_severity, test_size= 0.50, stratify = label_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(ratio='auto', kind='regular', random_state=42)\n",
    "smox, smoy = smote.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridSearch to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 500]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.05, 0.1, 0.01, 0.02],\n",
    "              'max_depth': [4,6],\n",
    "              'min_samples_leaf': [3,5,9,17],\n",
    "              'max_features': [1, 0.3, 0.1]}\n",
    "\n",
    "est = GradientBoostingClassifier(n_estimators = 3000)\n",
    "gs_cv = GridSearchCV(est, param_grid).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n",
    "\n",
    "# Random Forest\n",
    "'''\n",
    "{'bootstrap': True,\n",
    " 'max_depth': 110,\n",
    " 'max_features': 3,\n",
    " 'min_samples_leaf': 5,\n",
    " 'min_samples_split': 12,\n",
    " 'n_estimators': 100}\n",
    "'''\n",
    "\n",
    "# Gradient Boosting Tree\n",
    "'''\n",
    "{'learning_rate': 0.01,\n",
    " 'max_depth': 6,\n",
    " 'max_features': 0.3,\n",
    " 'min_samples_leaf': 9}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Random Fores/ Gradient Boosting Tree Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randome Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators = 100, \n",
    "                           bootstrap = True, \n",
    "                           max_depth = 35, \n",
    "                           max_features = 3, \n",
    "                           min_samples_leaf = 5,\n",
    "                           min_samples_split = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with data treated by SMOTE and predict.\n",
    "clf.fit(smox, smoy)\n",
    "ypred = clf.predict(x_test)\n",
    "print(classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graadient Boosting Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(n_estimators = 3000, \n",
    "                                 learning_rate = 0.01, \n",
    "                                 max_depth = 6, \n",
    "                                 max_features = 0.3, \n",
    "                                 min_samples_leaf = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt.fit(smox, smoy)\n",
    "ypred = gbrt.predict(x_test)\n",
    "print(classification_report(y_test, ypred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
